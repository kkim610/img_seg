{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82d757f1-81e8-42b9-b0aa-f1aa3338847b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# %load \"binary_to_coco_V3.0.py\"\n",
    "# https://youtu.be/NYeJvxe5nYw\n",
    "\"\"\"\n",
    "This code automates the conversion of binary masks representing different \n",
    "object categories into the COCO (Common Objects in Context) JSON format. \n",
    "\n",
    "The code is based on the following folder structure for training and validation\n",
    "images and masks. You need to change the code based on your folder structure \n",
    "or organize your data to the format below.\n",
    "\n",
    "EM-platelet-multi/   #Primary data folder for the project\n",
    "├── input/           #All input data is stored here. \n",
    "│   ├── train_images/\n",
    "│   │   ├── image01.png\n",
    "│   │   ├── image02.png\n",
    "│   │   └── ...\n",
    "│   ├── train_masks/        #All binary masks organized in respective sub-directories.\n",
    "│   │   ├── Alpha/\n",
    "│   │   │   ├── image01.png\n",
    "│   │   │   ├── image02.png\n",
    "│   │   │   └── ...\n",
    "│   │   ├── Cells/\n",
    "│   │   │   ├── image01.png\n",
    "│   │   │   ├── image02.png\n",
    "│   │   │   └── ...\n",
    "│   │   ├── Mito/\n",
    "│   │   │   ├── image01.png\n",
    "│   │   │   ├── image02.png\n",
    "│   │   │   └── ...\n",
    "│   │   └── Vessels/\n",
    "│   │       ├── image01.png\n",
    "│   │       ├── image02.png\n",
    "│   │       └── ...\n",
    "│   ├── val_images/\n",
    "│   │   ├── image05.png\n",
    "│   │   ├── image06.png\n",
    "│   │   └── ...\n",
    "│   └── val_masks/\n",
    "│       ├── Alpha/\n",
    "│       │   ├── image05.png\n",
    "│       │   ├── image06.png\n",
    "│       │   └── ...\n",
    "│       ├── Cells/\n",
    "│       │   ├── image05.png\n",
    "│       │   ├── image06.png\n",
    "│       │   └── ...\n",
    "│       ├── Mito/\n",
    "│       │   ├── image05.png\n",
    "│       │   ├── image06.png\n",
    "│       │   └── ...\n",
    "│       └── Vessels/\n",
    "│           ├── image05.png\n",
    "│           ├── image06.png\n",
    "│           └── ...\n",
    "└── ...\n",
    "\n",
    "\n",
    "For each binary mask, the code extracts contours using OpenCV. \n",
    "These contours represent the boundaries of objects within the images.This is a key\n",
    "step in converting binary masks to polygon-like annotations. \n",
    "\n",
    "Convert the contours into annotations, including \n",
    "bounding boxes, area, and segmentation information. Each annotation is \n",
    "associated with an image ID, category ID, and other properties required by the COCO format.\n",
    "\n",
    "The code also creates an images section containing \n",
    "metadata about the images, such as their filenames, widths, and heights.\n",
    "In my example, I have used exactly the same file names for all images and masks\n",
    "so that a given mask can be easily mapped to the image. \n",
    "\n",
    "All the annotations, images, and categories are \n",
    "assembled into a dictionary that follows the COCO JSON format. \n",
    "This includes sections for \"info,\" \"licenses,\" \"images,\" \"categories,\" and \"annotations.\"\n",
    "\n",
    "Finally, the assembled COCO JSON data is saved to a file, \n",
    "making it ready to be used with tools and frameworks that support the COCO data format.\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "from matplotlib import pyplot as plt\n",
    "import glob\n",
    "import json\n",
    "import os\n",
    "import cv2\n",
    "\n",
    "obj_name=\"speed_hump\"\n",
    "# Label IDs of the dataset representing different categories\n",
    "category_ids = {\n",
    "    \"speed_hump\": 1\n",
    "}\n",
    "\n",
    "MASK_EXT = 'png'\n",
    "ORIGINAL_EXT = 'png'\n",
    "image_id = 0\n",
    "annotation_id = 0\n",
    "\n",
    "def images_annotations_info(maskpath):\n",
    "    \"\"\"\n",
    "    Process the binary masks and generate images and annotations information.\n",
    "\n",
    "    :param maskpath: Path to the directory containing binary masks\n",
    "    :return: Tuple containing images info, annotations info, and annotation count\n",
    "    \"\"\"\n",
    "    global image_id, annotation_id\n",
    "    annotations = []\n",
    "    images = []\n",
    " \n",
    "    # Iterate through categories and corresponding masks\n",
    "    for category in category_ids.keys():\n",
    "        print(\"category\",category)\n",
    "        for mask_image in glob.glob(os.path.join(maskpath, category, f'*.{MASK_EXT}')):\n",
    "            print(\"mask_image\", mask_image)\n",
    "            original_file_name = f'{os.path.basename(mask_image).split(\".\")[0]}.{ORIGINAL_EXT}'\n",
    "            mask_image_open = cv2.imread(mask_image)\n",
    "\n",
    "            # Get image dimensions\n",
    "            height, width, _ = mask_image_open.shape\n",
    "\n",
    "            # Create or find existing image annotation\n",
    "            if original_file_name not in map(lambda img: img['file_name'], images):\n",
    "                image = {\n",
    "                    \"id\": image_id + 1,\n",
    "                    \"width\": width,\n",
    "                    \"height\": height,\n",
    "                    \"file_name\": original_file_name}\n",
    "                \n",
    "                images.append(image)\n",
    "                image_id += 1\n",
    "            else:\n",
    "                image = [element for element in images if element['file_name'] == original_file_name][0]\n",
    "\n",
    "            # Find contours in the mask image\n",
    "            gray = cv2.cvtColor(mask_image_open, cv2.COLOR_BGR2GRAY)            \n",
    "            _, thresh = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)            \n",
    "            contours = cv2.findContours(thresh, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)[0]\n",
    "\n",
    "            # Create annotation for each contour\n",
    "            for contour in contours:\n",
    "                bbox = cv2.boundingRect(contour)\n",
    "                area = cv2.contourArea(contour)\n",
    "                segmentation = contour.flatten().tolist()\n",
    "\n",
    "                annotation = {\n",
    "                    \"iscrowd\": 0,\n",
    "                    \"id\": annotation_id,\n",
    "                    \"image_id\": image['id'],\n",
    "                    \"category_id\": category_ids[category],\n",
    "                    \"bbox\": bbox,\n",
    "                    \"area\": area,\n",
    "                    \"segmentation\": [segmentation],}\n",
    "                \n",
    "\n",
    "                # Add annotation if area is greater than zero\n",
    "                if area > 0:\n",
    "                    annotations.append(annotation)\n",
    "                    annotation_id += 1\n",
    "\n",
    "    return images, annotations, annotation_id\n",
    "\n",
    "\n",
    "def process_masks(mask_path, dest_json):\n",
    "    global image_id, annotation_id\n",
    "    image_id = 0\n",
    "    annotation_id = 0\n",
    "\n",
    "    # Initialize the COCO JSON format with categories\n",
    "    coco_format = {\"info\": {}, \n",
    "                   \"licenses\": [], \n",
    "                   \"images\": [], \n",
    "                   \"categories\": [{\"id\": value, \"name\": key, \"supercategory\": key} for key, value in category_ids.items()], \n",
    "                   \"annotations\": [],}\n",
    "\n",
    "    # Create images and annotations sections\n",
    "    coco_format[\"images\"], coco_format[\"annotations\"], annotation_cnt = images_annotations_info(mask_path)\n",
    "\n",
    "    # Save the COCO JSON to a file\n",
    "    with open(dest_json, \"w\") as outfile:\n",
    "        json.dump(coco_format, outfile, sort_keys=True, indent=4)\n",
    "\n",
    "    print(\"Created %d annotations for images in folder: %s\" % (annotation_cnt, mask_path))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    basic_dir = \"dataset3/\"+obj_name+\"/input/\"\n",
    "    train_mask_path = basic_dir+\"train/mask\"\n",
    "    train_json_path = basic_dir+\"train/train.json\"\n",
    "    process_masks(train_mask_path, train_json_path)\n",
    "\n",
    "    val_mask_path = basic_dir+\"val/mask\"\n",
    "    val_json_path = basic_dir+\"val/val.json\"\n",
    "    process_masks(val_mask_path, val_json_path)\n",
    "\n",
    "    test_mask_path = basic_dir+\"test/mask\"\n",
    "    test_json_path = basic_dir+\"test/test.json\"\n",
    "    process_masks(test_mask_path, test_json_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62a7f90f-cd23-45bc-9ae7-1c96247870aa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
