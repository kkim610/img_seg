{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/bnsreenu/python_for_microscopists/blob/master/334_training_YOLO_V8_EM_platelets_converted_labels.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2z_8X_-SzkYG"
   },
   "source": [
    "https://youtu.be/ytlhMAF6ok0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OaMOGB9u2xv9"
   },
   "source": [
    "# **Custom instance model training using YOLOv8**\n",
    "<p>\n",
    "This code walks you through the process of training a custom YOLO v8 model using your own data. Here, I am using a public dataset that shows multiple classes for segmentation. This is the same dataset from tutorial 330 (Detectron2) - https://youtu.be/cEgF0YknpZw\n",
    "\n",
    "<p>\n",
    "Dataset from: https://leapmanlab.github.io/dense-cell/\n",
    "<br>\n",
    "Direct link to the dataset: https://www.dropbox.com/s/68yclbraqq1diza/platelet_data_1219.zip\n",
    "\n",
    "**Data courtesy of:**\n",
    "Guay, M.D., Emam, Z.A.S., Anderson, A.B. et al. ​\n",
    "Dense cellular segmentation for EM using 2D–3D neural network ensembles. Sci Rep 11, 2561 (2021). ​\n",
    "<p>\n",
    "To prepare this dataset for YOLO, the binary masks were converted to the YOLO format. Please follow this tutorial to learn about this process. <br>\n",
    "(https://youtu.be/NYeJvxe5nYw)\n",
    "\n",
    "<p>\n",
    "\n",
    "If you already have annotations in COCO format JSON file, for example by annotating using makesense (https://www.makesense.ai/) then the annotations can be imported to Roboflow for conversion to YOLO format. Otherwise, if you are starting from scratch, just annotate datasets on Roboflow. (https://roboflow.com/). You just need to upload your images along with the JSON file and Roboflow will convert them to any other format, in our case YOLO v8. <p>\n",
    "\n",
    "For information about YOLO models: <p>\n",
    "https://docs.ultralytics.com/models/yolov8/#key-features\n",
    "<p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LhUopx5sGliq"
   },
   "source": [
    "**Install the required libraries:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jCES-JIWsp4D"
   },
   "source": [
    "Let us start by installing ultralytics library. All other libraries should be pre-installed on colab. If you are working on a local system, please make sure you install matplotlib, Pillow, numpy, Seaborn, and roboflow. You may also want to install pandas and other libraries depending on the task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BdecybPl_PxQ"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-OiBCpm4_P-r"
   },
   "outputs": [],
   "source": [
    "cd drive/My Drive/hojung/yolo_1023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "16DtJG9iNQ2H"
   },
   "outputs": [],
   "source": [
    "# Install the ultralytics package using pip\n",
    "!pip install ultralytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eotMLol5O5G0"
   },
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "from matplotlib import pyplot as plt\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d0apxZsj2xBh"
   },
   "source": [
    "**Import a model and populate it with pre-trained weights.**\n",
    "<p>\n",
    "Here, we are importing an instance segmentation model with weights. For a list of pre-trained models, checkout: https://docs.ultralytics.com/models/yolov8/#key-features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bfhadgmPUWTm"
   },
   "outputs": [],
   "source": [
    "#Instance\n",
    "model = YOLO('yolov8n-seg.yaml')  # build a new model from YAML\n",
    "model = YOLO('yolov8n-seg.pt')  # Transfer the weights from a pretrained model (recommended for training)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6BFiNz2LtFxJ"
   },
   "source": [
    "**Install Roboflow**\n",
    "<p>\n",
    "to directly read our training data. For colab, we are going to find a workaround to handle encoding issues by the platform. In fact, we may encounter encoding issues for other tasks in Colab so let's go ahead and run the following cell.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0pBNHHqscZ9p"
   },
   "outputs": [],
   "source": [
    "#Withut this Colab is giving an error when installing Roboflow\n",
    "import locale\n",
    "locale.getpreferredencoding = lambda: \"UTF-8\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tdHoSArbHt_a"
   },
   "source": [
    "In case your annotations are on Roboflow, you can directly import the training data using your API key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IvH95KHtcOK_"
   },
   "outputs": [],
   "source": [
    "#!pip install roboflow --quiet\n",
    "#%cd /content/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jCWmDLFdI5Ky"
   },
   "outputs": [],
   "source": [
    "# To hide your API key from others, you can use getpass\n",
    "#from getpass import getpass\n",
    "#token = getpass('Enter Token Here') #I stored my token in a file on my Google Drive. I will enter it when prompted here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_KvMGSaqa2JI"
   },
   "outputs": [],
   "source": [
    "# Import your data from Roboflow\n",
    "\"\"\"\n",
    "from roboflow import Roboflow\n",
    "rf = Roboflow(api_key=token)\n",
    "project = rf.workspace(\"python-for-microscopists-nceyk\").project(\"3d-em-platelet\")\n",
    "dataset = project.version(2).download(\"yolov8\")\n",
    "\"\"\"\n",
    "#Change the working directory to the downloaded data directory and check the yaml file.\n",
    "#%cd /content/your_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0ucPAX1O38xv"
   },
   "source": [
    "Let us load the YAML file that contains the names of our classes, number of classes and the directories for train, valid, and test datasets, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vVzvL6d1fhGH"
   },
   "outputs": [],
   "source": [
    "# this is the YAML file Roboflow wrote for us that we're loading into this notebook with our data\n",
    "#%cat /content/drive/MyDrive/ColabNotebooks/data/3D-EM-Platelet/YOLOV8-data/data.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OtcPQNFyD_3s"
   },
   "outputs": [],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WgxXtFtK88M8"
   },
   "outputs": [],
   "source": [
    "obj_name=\"speed_hump\"\n",
    "yaml_name=\"data_\"+obj_name+\".yaml\"\n",
    "proj_fname = obj_name+\"-\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iEx0vgEs7Lzx"
   },
   "outputs": [],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6-9DlovCf3e-"
   },
   "outputs": [],
   "source": [
    "# define number of classes based on YAML\n",
    "import yaml\n",
    "#with open(\"/content/drive/MyDrive/ColabNotebooks/data/3D-EM-Platelet/YOLOV8-data/data.yaml\", 'r') as stream:\n",
    "with open(yaml_name, 'r') as stream:\n",
    "    num_classes = str(yaml.safe_load(stream)['nc'])\n",
    "    print( num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Mxm0iW8vLCDo"
   },
   "source": [
    "**Train the model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b7JOR8RrpXtZ"
   },
   "outputs": [],
   "source": [
    "#Define a project --> Destination directory for all results\n",
    "project = \"hojung_results\"\n",
    "#Define subdirectory for this specific training\n",
    "name = proj_fname #note that if you run the training again, it creates a directory: 200_epochs-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "G8vJK4BsJaoZ"
   },
   "outputs": [],
   "source": [
    "# Train the model\n",
    "results = model.train(data=yaml_name,\n",
    "                      project=project,\n",
    "                      name=name,\n",
    "                      epochs=20,\n",
    "                      patience=0, #I am setting patience=0 to disable early stopping.\n",
    "                      batch=8,\n",
    "                      imgsz=512)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W3ylq4uvLG8y"
   },
   "source": [
    "All training curves, metrics, and other results are stored as images in the 'runs' directory. Let us open a couple of these images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "z2PpCJBUh2E6"
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VVjGUgq6h1iq"
   },
   "outputs": [],
   "source": [
    "Image(\"hojung_results/\"+proj_fname+\"/results.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dmbBmrKAuMCq"
   },
   "outputs": [],
   "source": [
    "Image(filename=\"hojung_results/\"+proj_fname+\"/train_batch1.jpg\", width=900)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rNq5pLQJurtl"
   },
   "source": [
    "**Run inference**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OkIJB__zLXm9"
   },
   "source": [
    "Now that our model is trained, we can use it for inference."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3cue9KgoLn-e"
   },
   "source": [
    "You can load the best model or the latest. I am picking the latest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HzzGWix5KEPm"
   },
   "outputs": [],
   "source": [
    "\"hojung_results/\"+proj_fname+\"/weights/best.pt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "t5PjdDqQvdRQ"
   },
   "outputs": [],
   "source": [
    "my_new_model = YOLO(\"hojung_results/\"+proj_fname+\"/weights/best.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5Zp9QZeYBfxF"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "import os\n",
    "test_dir2=\"datasets/test/\"+obj_name\n",
    "test_dir_mask=test_dir2+\"/mask/\"+obj_name\n",
    "test_dir=test_dir2+\"/images\"\n",
    "conf_D={}\n",
    "\n",
    "for confidence_value in range(1, 9):\n",
    "    confidence_value = confidence_value/10\n",
    "    print(confidence_value)\n",
    "\n",
    "    new_results = my_new_model.predict(test_dir, imgsz=512, conf=confidence_value)  #Adjust conf threshold\n",
    "\n",
    "    L_A=[]\n",
    "    for i in range(len(new_results)):\n",
    "        if  new_results[i].masks:\n",
    "            pred_A=new_results[i].masks.data.cpu().numpy()\n",
    "        else:\n",
    "            pred_A=np.zeros((512,512))\n",
    "        L_A.append(pred_A)\n",
    "\n",
    "    LL=os.listdir(test_dir_mask)\n",
    "    LL.sort()\n",
    "    TOT=np.zeros(5)\n",
    "    tot_pixel = 512*512\n",
    "    for i in range(len(L_A)):\n",
    "        if L_A[i].ndim==3:\n",
    "            k,_,_=L_A[i].shape\n",
    "            mask_pred_A=np.zeros((512,512))\n",
    "\n",
    "            for j in range(k):\n",
    "                mask_pred_A +=L_A[i][j]\n",
    "\n",
    "        else:\n",
    "            mask_pred_A = L_A[i]\n",
    "        mask_pred_A[mask_pred_A>0.5]=1\n",
    "        mask_A = np.array(Image.open(test_dir_mask+\"/\"+LL[i]))\n",
    "        mask_A=mask_A[:,:,0]\n",
    "        mask_A[mask_A > 1]=1\n",
    "        overlap = np.sum(mask_A*mask_pred_A) # Logical AND\n",
    "        union = mask_A + mask_pred_A # Logical OR\n",
    "        union[union > 1]=1\n",
    "        union = np.sum(union)\n",
    "\n",
    "        if mask_pred_A.sum() < 0.1:\n",
    "            Precision = 0.0\n",
    "        else:\n",
    "            Precision = np.sum(overlap)/np.sum(mask_pred_A)\n",
    "        Recall = overlap/np.sum(mask_A)\n",
    "\n",
    "        if (Precision+Recall) == 0:\n",
    "            F1 = 0.0\n",
    "        else:\n",
    "            F1 = (2*Precision*Recall)/(Precision+Recall)\n",
    "\n",
    "        IOU = overlap/union\n",
    "\n",
    "        Pixel_Accuracy = np.sum(np.sum(mask_pred_A == mask_A))/tot_pixel\n",
    "\n",
    "        tot = np.array([Precision,Recall,F1,IOU,Pixel_Accuracy])\n",
    "\n",
    "        TOT = TOT + tot\n",
    "\n",
    "    print(\"TOTALLLLL:\",TOT/len(L_A))\n",
    "    conf_D[confidence_value]=TOT/len(L_A)\n",
    "conf_D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cENtLn-2BnK2"
   },
   "outputs": [],
   "source": [
    "print(zzz)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
