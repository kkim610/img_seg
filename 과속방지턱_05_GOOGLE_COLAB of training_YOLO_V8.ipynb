{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"A100"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"view-in-github"},"source":["<a href=\"https://colab.research.google.com/github/bnsreenu/python_for_microscopists/blob/master/334_training_YOLO_V8_EM_platelets_converted_labels.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"]},{"cell_type":"markdown","source":["https://youtu.be/ytlhMAF6ok0"],"metadata":{"id":"2z_8X_-SzkYG"}},{"cell_type":"markdown","source":["# **Custom instance model training using YOLOv8**\n","<p>\n","This code walks you through the process of training a custom YOLO v8 model using your own data. Here, I am using a public dataset that shows multiple classes for segmentation. This is the same dataset from tutorial 330 (Detectron2) - https://youtu.be/cEgF0YknpZw\n","\n","<p>\n","Dataset from: https://leapmanlab.github.io/dense-cell/\n","<br>\n","Direct link to the dataset: https://www.dropbox.com/s/68yclbraqq1diza/platelet_data_1219.zip\n","\n","**Data courtesy of:**\n","Guay, M.D., Emam, Z.A.S., Anderson, A.B. et al. ​\n","Dense cellular segmentation for EM using 2D–3D neural network ensembles. Sci Rep 11, 2561 (2021). ​\n","<p>\n","To prepare this dataset for YOLO, the binary masks were converted to the YOLO format. Please follow this tutorial to learn about this process. <br>\n","(https://youtu.be/NYeJvxe5nYw)\n","\n","<p>\n","\n","If you already have annotations in COCO format JSON file, for example by annotating using makesense (https://www.makesense.ai/) then the annotations can be imported to Roboflow for conversion to YOLO format. Otherwise, if you are starting from scratch, just annotate datasets on Roboflow. (https://roboflow.com/). You just need to upload your images along with the JSON file and Roboflow will convert them to any other format, in our case YOLO v8. <p>\n","\n","For information about YOLO models: <p>\n","https://docs.ultralytics.com/models/yolov8/#key-features\n","<p>\n"],"metadata":{"id":"OaMOGB9u2xv9"}},{"cell_type":"markdown","source":["**Install the required libraries:**"],"metadata":{"id":"LhUopx5sGliq"}},{"cell_type":"markdown","source":["Let us start by installing ultralytics library. All other libraries should be pre-installed on colab. If you are working on a local system, please make sure you install matplotlib, Pillow, numpy, Seaborn, and roboflow. You may also want to install pandas and other libraries depending on the task."],"metadata":{"id":"jCES-JIWsp4D"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"BdecybPl_PxQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["cd drive/My Drive/hojung/yolo_1023"],"metadata":{"id":"-OiBCpm4_P-r"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Install the ultralytics package using pip\n","!pip install ultralytics"],"metadata":{"id":"16DtJG9iNQ2H"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from ultralytics import YOLO\n","from matplotlib import pyplot as plt\n","from PIL import Image"],"metadata":{"id":"eotMLol5O5G0"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Import a model and populate it with pre-trained weights.**\n","<p>\n","Here, we are importing an instance segmentation model with weights. For a list of pre-trained models, checkout: https://docs.ultralytics.com/models/yolov8/#key-features"],"metadata":{"id":"d0apxZsj2xBh"}},{"cell_type":"code","source":["#Instance\n","model = YOLO('yolov8n-seg.yaml')  # build a new model from YAML\n","model = YOLO('yolov8n-seg.pt')  # Transfer the weights from a pretrained model (recommended for training)"],"metadata":{"id":"bfhadgmPUWTm"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Install Roboflow**\n","<p>\n","to directly read our training data. For colab, we are going to find a workaround to handle encoding issues by the platform. In fact, we may encounter encoding issues for other tasks in Colab so let's go ahead and run the following cell.  "],"metadata":{"id":"6BFiNz2LtFxJ"}},{"cell_type":"code","source":["#Withut this Colab is giving an error when installing Roboflow\n","import locale\n","locale.getpreferredencoding = lambda: \"UTF-8\""],"metadata":{"id":"0pBNHHqscZ9p"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["In case your annotations are on Roboflow, you can directly import the training data using your API key"],"metadata":{"id":"tdHoSArbHt_a"}},{"cell_type":"code","source":["#!pip install roboflow --quiet\n","#%cd /content/"],"metadata":{"id":"IvH95KHtcOK_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# To hide your API key from others, you can use getpass\n","#from getpass import getpass\n","#token = getpass('Enter Token Here') #I stored my token in a file on my Google Drive. I will enter it when prompted here."],"metadata":{"id":"jCWmDLFdI5Ky"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Import your data from Roboflow\n","\"\"\"\n","from roboflow import Roboflow\n","rf = Roboflow(api_key=token)\n","project = rf.workspace(\"python-for-microscopists-nceyk\").project(\"3d-em-platelet\")\n","dataset = project.version(2).download(\"yolov8\")\n","\"\"\"\n","#Change the working directory to the downloaded data directory and check the yaml file.\n","#%cd /content/your_dataset"],"metadata":{"id":"_KvMGSaqa2JI"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Let us load the YAML file that contains the names of our classes, number of classes and the directories for train, valid, and test datasets, respectively."],"metadata":{"id":"0ucPAX1O38xv"}},{"cell_type":"code","source":["# this is the YAML file Roboflow wrote for us that we're loading into this notebook with our data\n","#%cat /content/drive/MyDrive/ColabNotebooks/data/3D-EM-Platelet/YOLOV8-data/data.yaml"],"metadata":{"id":"vVzvL6d1fhGH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["pwd"],"metadata":{"id":"OtcPQNFyD_3s"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["obj_name=\"speed_hump\"\n","yaml_name=\"data_\"+obj_name+\".yaml\"\n","proj_fname = obj_name+\"-\""],"metadata":{"id":"WgxXtFtK88M8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["ls"],"metadata":{"id":"iEx0vgEs7Lzx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# define number of classes based on YAML\n","import yaml\n","#with open(\"/content/drive/MyDrive/ColabNotebooks/data/3D-EM-Platelet/YOLOV8-data/data.yaml\", 'r') as stream:\n","with open(yaml_name, 'r') as stream:\n","    num_classes = str(yaml.safe_load(stream)['nc'])\n","    print( num_classes)"],"metadata":{"id":"6-9DlovCf3e-"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Train the model**"],"metadata":{"id":"Mxm0iW8vLCDo"}},{"cell_type":"code","source":["#Define a project --> Destination directory for all results\n","project = \"hojung_results\"\n","#Define subdirectory for this specific training\n","name = proj_fname #note that if you run the training again, it creates a directory: 200_epochs-2"],"metadata":{"id":"b7JOR8RrpXtZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Train the model\n","results = model.train(data=yaml_name,\n","                      project=project,\n","                      name=name,\n","                      epochs=20,\n","                      patience=0, #I am setting patience=0 to disable early stopping.\n","                      batch=8,\n","                      imgsz=512)"],"metadata":{"id":"G8vJK4BsJaoZ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["All training curves, metrics, and other results are stored as images in the 'runs' directory. Let us open a couple of these images."],"metadata":{"id":"W3ylq4uvLG8y"}},{"cell_type":"code","source":["from IPython.display import Image"],"metadata":{"id":"z2PpCJBUh2E6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["Image(\"hojung_results/\"+proj_fname+\"/results.png\")"],"metadata":{"id":"VVjGUgq6h1iq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["Image(filename=\"hojung_results/\"+proj_fname+\"/train_batch1.jpg\", width=900)"],"metadata":{"id":"dmbBmrKAuMCq"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Run inference**"],"metadata":{"id":"rNq5pLQJurtl"}},{"cell_type":"markdown","source":["Now that our model is trained, we can use it for inference."],"metadata":{"id":"OkIJB__zLXm9"}},{"cell_type":"markdown","source":["You can load the best model or the latest. I am picking the latest."],"metadata":{"id":"3cue9KgoLn-e"}},{"cell_type":"code","source":["\"hojung_results/\"+proj_fname+\"/weights/best.pt\""],"metadata":{"id":"HzzGWix5KEPm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["my_new_model = YOLO(\"hojung_results/\"+proj_fname+\"/weights/best.pt\")"],"metadata":{"id":"t5PjdDqQvdRQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import numpy as np\n","from PIL import Image\n","import os\n","test_dir2=\"datasets/test/\"+obj_name\n","test_dir_mask=test_dir2+\"/mask/\"+obj_name\n","test_dir=test_dir2+\"/images\"\n","conf_D={}\n","\n","for confidence_value in range(1, 9):\n","    confidence_value = confidence_value/10\n","    print(confidence_value)\n","\n","    new_results = my_new_model.predict(test_dir, imgsz=512, conf=confidence_value)  #Adjust conf threshold\n","\n","    L_A=[]\n","    for i in range(len(new_results)):\n","        if  new_results[i].masks:\n","            pred_A=new_results[i].masks.data.cpu().numpy()\n","        else:\n","            pred_A=np.zeros((512,512))\n","        L_A.append(pred_A)\n","\n","    LL=os.listdir(test_dir_mask)\n","    LL.sort()\n","    #print(LL)\n","    TOT=np.zeros(5)\n","    #print(TOT)\n","    tot_pixel = 512*512\n","    for i in range(len(L_A)):\n","        if L_A[i].ndim==3:\n","            k,_,_=L_A[i].shape\n","            mask_pred_A=np.zeros((512,512))\n","            #print(\"L_A[i][0].shape\",L_A[i][0].shape)\n","            for j in range(k):\n","                mask_pred_A +=L_A[i][j]\n","            #print(\"mask_pred_A.shape\",mask_pred_A.shape)\n","\n","        else:\n","            mask_pred_A = L_A[i]\n","        mask_pred_A[mask_pred_A>0.5]=1\n","        mask_A = np.array(Image.open(test_dir_mask+\"/\"+LL[i]))\n","        mask_A=mask_A[:,:,0]\n","        mask_A[mask_A > 1]=1\n","        overlap = np.sum(mask_A*mask_pred_A) # Logical AND\n","        union = mask_A + mask_pred_A # Logical OR\n","        union[union > 1]=1\n","        union = np.sum(union)\n","\n","        #print(\"np.unique\", np.unique(mask_pred_A), np.unique(mask_A))\n","        #print(\"mask_pred_A.shape\",mask_pred_A.shape)\n","        #print(\"mask_A.shape\",mask_A.shape)\n","        #print(\"mask_A.sum()\",np.sum(mask_A))\n","        #print(\"overlap.sum()\",np.sum(overlap), overlap.shape)\n","        #print(\"union.sum()\",np.sum(union)\n","        #print(\"mask_pred_A.sum()\",np.sum(mask_pred_A))\n","\n","        if mask_pred_A.sum() < 0.1:\n","            Precision = 0.0\n","        else:\n","            Precision = np.sum(overlap)/np.sum(mask_pred_A)\n","        Recall = overlap/np.sum(mask_A)\n","\n","        if (Precision+Recall) == 0:\n","            F1 = 0.0\n","        else:\n","            F1 = (2*Precision*Recall)/(Precision+Recall)\n","        #print(\"Precision:\",Precision)\n","        #print(\"Recall:\",Recall)\n","        #print(\"F1:\",F1)\n","\n","\n","        IOU = overlap/union\n","\n","        Pixel_Accuracy = np.sum(np.sum(mask_pred_A == mask_A))/tot_pixel\n","\n","        #print(\"IOU:\",IOU)\n","        #print(\"Pixel_Accuracy:\",Pixel_Accuracy)\n","\n","        tot = np.array([Precision,Recall,F1,IOU,Pixel_Accuracy])\n","        #print(\"tot\",tot)\n","        TOT = TOT + tot\n","        #print(\"TOT\",TOT)\n","        #print(IOU)\n","        #if i == 5:\n","        #    print(zzz)\n","    print(\"TOTALLLLL:\",TOT/len(L_A))\n","    conf_D[confidence_value]=TOT/len(L_A)\n","conf_D"],"metadata":{"id":"5Zp9QZeYBfxF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(zzz)"],"metadata":{"id":"cENtLn-2BnK2"},"execution_count":null,"outputs":[]}]}